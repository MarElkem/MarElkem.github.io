[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mini-Project 1: Maps (Static)",
    "section": "",
    "text": "For this miniproject, we will be looking at data collected by the Consumer Financial Protection Bureau of complaints about consumer financial products and services from 06/01/24 to 09/10/24\n\n#use the states dataset for interactive map plots and rename the column \"name\" which indicates state in order to join with our variable dataset.\nstates &lt;- states %&gt;%\n  rename(region = name) %&gt;%               \n  mutate(region = tolower(region))        \n\nstates  \n\n\n#rename all states in our complaint dataset to match with us_states and states\ncomplaints &lt;- complaints |&gt; \n   mutate(region = case_when(\n    State == \"AL\" ~ \"alabama\", State == \"AK\" ~ \"alaska\", State == \"AZ\" ~ \"arizona\",\n    State == \"AR\" ~ \"arkansas\", State == \"CA\" ~ \"california\", State == \"CO\" ~ \"colorado\",\n    State == \"CT\" ~ \"connecticut\", State == \"DE\" ~ \"delaware\", State == \"FL\" ~ \"florida\",\n    State == \"GA\" ~ \"georgia\", State == \"HI\" ~ \"hawaii\", State == \"ID\" ~ \"idaho\",\n    State == \"IL\" ~ \"illinois\", State == \"IN\" ~ \"indiana\", State == \"IA\" ~ \"iowa\",\n    State == \"KS\" ~ \"kansas\", State == \"KY\" ~ \"kentucky\", State == \"LA\" ~ \"louisiana\",\n    State == \"ME\" ~ \"maine\", State == \"MD\" ~ \"maryland\", State == \"MA\" ~ \"massachusetts\",\n    State == \"MI\" ~ \"michigan\", State == \"MN\" ~ \"minnesota\", State == \"MS\" ~ \"mississippi\",\n    State == \"MO\" ~ \"missouri\", State == \"MT\" ~ \"montana\", State == \"NE\" ~ \"nebraska\",\n    State == \"NV\" ~ \"nevada\", State == \"NH\" ~ \"new hampshire\", State == \"NJ\" ~ \"new jersey\",\n    State == \"NM\" ~ \"new mexico\", State == \"NY\" ~ \"new york\", State == \"NC\" ~ \"north carolina\",\n    State == \"ND\" ~ \"north dakota\", State == \"OH\" ~ \"ohio\", State == \"OK\" ~ \"oklahoma\",\n    State == \"OR\" ~ \"oregon\", State == \"PA\" ~ \"pennsylvania\", State == \"RI\" ~ \"rhode island\",\n    State == \"SC\" ~ \"south carolina\", State == \"SD\" ~ \"south dakota\", State == \"TN\" ~ \"tennessee\",\n    State == \"TX\" ~ \"texas\", State == \"UT\" ~ \"utah\", State == \"VT\" ~ \"vermont\",\n    State == \"VA\" ~ \"virginia\", State == \"WA\" ~ \"washington\", State == \"WV\" ~ \"west virginia\",\n    State == \"WI\" ~ \"wisconsin\", State == \"WY\" ~ \"wyoming\"\n  )) \n\n\n#create our first subset of our dataset: most complaining states!\n\ncomplaints_summary &lt;- complaints %&gt;% \n  group_by(region) %&gt;% \n  summarize(total_complaints = n())\n\ncomplaints_summary &lt;- complaints_summary %&gt;%  # save it and join with us_states for static plot\n  left_join(us_states, by = \"region\")\n\n\n\nPLOT 1\n\n\n\nlbeel &lt;- complaints_summary %&gt;% # save our labels\n  group_by(region) %&gt;%\n  summarize(long = mean(long), lat = mean(lat)) %&gt;% # center the labels on the middle of every state\n  mutate(region = as.factor(region))\n\nstatic1 &lt;- complaints_summary |&gt;\n  ggplot(mapping = aes(x = long, y = lat)) + \n  geom_polygon(aes(fill = total_complaints, group = group), color = \"black\") + \n  labs(\n    fill = \"Number of Complaints\",\n    caption = \"Data Source: https://www.consumerfinance.gov/\n    Consumer Financial Protection Bureau \n    (Complaints from 06/01/2024 - 09/10/2024)\"\n  ) +\n  coord_map() + \n  scale_fill_viridis_c() +\n  geom_text(\n    data = lbeel, \n    mapping = aes(x = long, y = lat, label = region), \n    size = 3, \n    color = \"white\"\n  )\n\nstatic1\n\n\n\n\n\n\n\n\nWe have a US state map showing the number of complaints from 06/01/24 to 09/10/24 against companies that were gathered on The Consumer Complaint Database- a collection of complaints about consumer financial products and services. We can see color-coding for each state with a legend on the right showing us the ranges of the different color assignments from purple(0-20k complaints)-blue(20-40k complaints)-teal(30-60k complaints)-green/yellow(60-80k+ complaints). All the states are purple except 7 states. In order of most complaints:\nYellow : Florida (80k), Texas (~70k) Green: California (60K), Georgia (50k) Blue: Illinois (35k), Pennsylvania (30K), New York (40k)\nThe graph shows that the highest number of complaints is coming from Flordia, and the least coming from Alabama (10k) and the average complaint number per state is 20k\n\n\nPLOT 2\n\n\n\nlbeel2 &lt;- complaints_summary %&gt;%\n  group_by(region) %&gt;%\n  summarize(long = mean(long), lat = mean(lat)) %&gt;%\n  mutate(region = as.factor(region))\n\nstatic2 &lt;- staticcompany |&gt;\n  ggplot(mapping = aes(x = long, y = lat)) + \n  geom_polygon(aes(fill = Company, group = group), color = \"black\") + \n  labs(\n    fill = \"Company Complained About\",\n    caption = \"Data Source: https://www.consumerfinance.gov/\n    Consumer Financial Protection Bureau \n    (Complaints from 06/01/2024 - 09/10/2024)\"\n  ) +\n  coord_map() + \n  scale_fill_viridis_d() +\n  geom_text(\n    data = lbeel2, \n    mapping = aes(x = long, y = lat, label = region), \n    size = 3, \n    color = \"white\"\n  )\n\nstatic2\n\n\n\n\n\n\n\n\nOur plot informs us of the 3 most complained about companies- which are Transunion (a credit reporting agency headquarted in Chicago, Illinois), (Experian is a multinational data analytics and consumer credit reporting company headquartered in Dublin, Ireland), and Equifax (a consumer credit reporting agency headquartered in Atlanta, Georgia), Experian Information Solutions. The States who complain the most about Equifax are WA, OR, ID, WY, NE, KA, MI, TE, KE, WV, OH, NC, VI, MS, AL, LO. For Experian, it is MO and ND only- and all the rest are TransUnion."
  },
  {
    "objectID": "about2.html",
    "href": "about2.html",
    "title": "Mini-Project 1: Maps (Interactive)",
    "section": "",
    "text": "This is a continuation of MP1, where we have the same insights and data but in an interactive form!\n\n#rename all states in our complaint dataset to match with us_states and states\ncomplaints &lt;- complaints |&gt; \n   mutate(region = case_when(\n    State == \"AL\" ~ \"alabama\", State == \"AK\" ~ \"alaska\", State == \"AZ\" ~ \"arizona\",\n    State == \"AR\" ~ \"arkansas\", State == \"CA\" ~ \"california\", State == \"CO\" ~ \"colorado\",\n    State == \"CT\" ~ \"connecticut\", State == \"DE\" ~ \"delaware\", State == \"FL\" ~ \"florida\",\n    State == \"GA\" ~ \"georgia\", State == \"HI\" ~ \"hawaii\", State == \"ID\" ~ \"idaho\",\n    State == \"IL\" ~ \"illinois\", State == \"IN\" ~ \"indiana\", State == \"IA\" ~ \"iowa\",\n    State == \"KS\" ~ \"kansas\", State == \"KY\" ~ \"kentucky\", State == \"LA\" ~ \"louisiana\",\n    State == \"ME\" ~ \"maine\", State == \"MD\" ~ \"maryland\", State == \"MA\" ~ \"massachusetts\",\n    State == \"MI\" ~ \"michigan\", State == \"MN\" ~ \"minnesota\", State == \"MS\" ~ \"mississippi\",\n    State == \"MO\" ~ \"missouri\", State == \"MT\" ~ \"montana\", State == \"NE\" ~ \"nebraska\",\n    State == \"NV\" ~ \"nevada\", State == \"NH\" ~ \"new hampshire\", State == \"NJ\" ~ \"new jersey\",\n    State == \"NM\" ~ \"new mexico\", State == \"NY\" ~ \"new york\", State == \"NC\" ~ \"north carolina\",\n    State == \"ND\" ~ \"north dakota\", State == \"OH\" ~ \"ohio\", State == \"OK\" ~ \"oklahoma\",\n    State == \"OR\" ~ \"oregon\", State == \"PA\" ~ \"pennsylvania\", State == \"RI\" ~ \"rhode island\",\n    State == \"SC\" ~ \"south carolina\", State == \"SD\" ~ \"south dakota\", State == \"TN\" ~ \"tennessee\",\n    State == \"TX\" ~ \"texas\", State == \"UT\" ~ \"utah\", State == \"VT\" ~ \"vermont\",\n    State == \"VA\" ~ \"virginia\", State == \"WA\" ~ \"washington\", State == \"WV\" ~ \"west virginia\",\n    State == \"WI\" ~ \"wisconsin\", State == \"WY\" ~ \"wyoming\"\n  )) \n\n\n#use the states dataset for interactive map plots and rename the column \"name\" which indicates state in order to join with our variable dataset.\nstates &lt;- states %&gt;%\n  rename(region = name) %&gt;%               \n  mutate(region = tolower(region))        \n\n\n#create our first subset of our dataset: most complaining states!\n\ncomplaints_summary &lt;- complaints %&gt;% \n  group_by(region) %&gt;% \n  summarize(total_complaints = n())\n\n\n# save it and join with us_states for interactive plot\ncomplaints_geo &lt;- complaints_summary %&gt;%\n  left_join(states, by = \"region\") %&gt;% \n  st_as_sf()\n\n\nleaflet(complaints_geo) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(\n    fillColor = ~colorNumeric(\"viridis\", complaints_geo$total_complaints)(total_complaints), #we want to show the variable \"total complaints\"\n    weight = 1,\n    color = \"black\",\n    fillOpacity = 0.7,\n    label = ~paste(region, \"Complaints:\", total_complaints) #pop-up label format\n  ) %&gt;%\n  addLegend(\n    pal = colorNumeric(\"viridis\", complaints_geo$total_complaints), \n    values = complaints_geo$total_complaints,\n    title = \"Number of Complaints\",\n    position = \"bottomright\"\n  ) %&gt;% \n  addControl(\n    html = \"Data Source: &lt;a href='https://www.consumerfinance.gov/'&gt;Consumer Financial Protection Bureau&lt;/a&gt; (Complaints from 06/01/2024 - 09/10/2024)\", \n    position = \"bottomleft\"\n  )\n\n\n\n\n\nHover over the states to see how many complaints they have filed!\n\n#second interactive plot, most complained about companies!\ncomplaints_company2 &lt;- complaints %&gt;%\n  group_by(region, Company) %&gt;%\n  summarize(complaint_count = n(), .groups = \"drop\") %&gt;%  \n  slice_max(order_by = complaint_count, n = 1, by=region, with_ties = FALSE)  #get the most complained about company for every state\n\n\n#join it to our interactive mapping dataset, state\ninteractivecompany &lt;- complaints_company2 %&gt;% \n  left_join(states, by=\"region\") %&gt;% \n    st_as_sf()\n\n\nbinColor &lt;- colorFactor(palette = \"Set3\", domain = interactivecompany$Company)\n\ninteractivecompany &lt;- interactivecompany %&gt;%\n  mutate(labels = lapply(paste0(\"&lt;strong&gt;State: \", region, \"&lt;/strong&gt;&lt;br/&gt;\", #create our labels\n                                \"Company: \", Company, \"&lt;br/&gt;\", \n                                \"Complaints: \", complaint_count), \n                         HTML))\n\nleaflet(interactivecompany) %&gt;%\n  setView(lng = -96, lat = 37.8, zoom = 4) %&gt;%  #focus the map on the US\n  addTiles() %&gt;%\n  addPolygons(\n    weight = 2,\n    opacity = 1,\n    fillColor = ~binColor(Company),  \n    color = \"black\",\n    dashArray = \"3\",\n    fillOpacity = 0.7,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"#666\",\n      dashArray = \"\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE\n    ),\n    label = ~labels,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\"\n    )\n  ) %&gt;% \n  addControl(\n    html = \"Data Source: &lt;a href='https://www.consumerfinance.gov/'&gt;Consumer Financial Protection \n    Bureau&lt;/a&gt; (Complaints from 06/01/2024 - 09/10/2024)\", \n    position = \"bottomleft\"\n  )\n\n\n\n\n\nHover over the states to see what company they have complained about the most!"
  },
  {
    "objectID": "about3.html",
    "href": "about3.html",
    "title": "Mini-Project 2: Data Acquisition",
    "section": "",
    "text": "Data Source: https://fbref.com/en/comps/1/World-Cup-Stat\nMotivation: as two avid football (soccer) fans. We are hoping to analyze and explore the World Cup 2022 data. we will also potentially explore the last 10 World Cups. We will do so by exploring player statistics, match standings data, and other external variables such as sentiment analysis and audience engagement.\nTwo similar questions we hope to explore are:\n\n\nIf there is a strong correlation between goals scored and points earned in the group stage\n\n\n\n\nDo points, goals scored, goals against, or goal difference have the highest impact on progression towards knockout/semi-finals stages.\n\n\nEthical Justification: We believe this data does not have ethical implications as long as it is scraped politely. One approach we will keep in mind is to clean and analyze various squads to get a representation of the real world rather than just focusing on popular squads\n\n#First we have to make sure scraping is allowed\nrobotstxt::paths_allowed(\"https://fbref.com/en/comps/1/World-Cup-Stats\")\n\n\n fbref.com                      \n\n#Next we scrape the data\nsession &lt;- bow(\"https://fbref.com/en/comps/1/World-Cup-Stats\")\n\n\n# Next we will store our session \nwc22 &lt;- scrape(session)\n\n# Next we will save our tables\ntables &lt;- html_nodes(wc22, css = \"table\")\n\n# Get all the groups we need\nhtml_table(tables, header = TRUE, fill = TRUE)   \nwc_group1 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[1]]  \nwc_group2 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[2]]  \nwc_group3 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[3]]  \nwc_group4 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[4]]  \nwc_group5 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[5]]  \nwc_group6 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[6]]  \nwc_group7 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[7]]  \nwc_group8 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[8]]  \n\n\n\nAbove we are scraping data of all the group stages of the 2022 World Cup\n\n\n\nall_groups &lt;- bind_rows(lapply(list(wc_group1, wc_group2, wc_group3, wc_group4,\n                                      wc_group5, wc_group6, wc_group7, wc_group8), function(group) {\n  # Rename columns\n  colnames(group) &lt;- c(\"Rank\", \"Squad\", \"Matches Played\", \"Wins\", \"Draws\", \"Losses\",\n                       \"Goals For\", \"Goals Against\", \"Goal Difference\", \"Points\")\n  \n  # Remove the first two-letter abbreviation from Squad names\n  group$Squad &lt;- str_replace(group$Squad, \"^[^ ]+ \", \"\")\n  \n  # Remove the xGD/90 column if it exists\n  if (\"xGD/90\" %in% colnames(group)) {\n    group &lt;- select(group, -`xGD/90`)\n  }\n  \n  return(group)\n}))\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n\n# Display the combined tibble\nall_groups\n\n# A tibble: 32 × 15\n    Rank Squad   `Matches Played`  Wins Draws Losses `Goals For` `Goals Against`\n   &lt;int&gt; &lt;chr&gt;              &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;       &lt;int&gt;           &lt;int&gt;\n 1     1 Nether…                3     2     1      0           5               1\n 2     2 Senegal                3     2     0      1           5               4\n 3     3 Ecuador                3     1     1      1           4               3\n 4     4 Qatar                  3     0     0      3           1               7\n 5     1 England                3     2     1      0           9               2\n 6     2 United…                3     1     2      0           2               1\n 7     3 IR Iran                3     1     0      2           4               7\n 8     4 Wales                  3     0     1      2           1               6\n 9     1 Argent…                3     2     0      1           5               2\n10     2 Poland                 3     1     1      1           2               2\n# ℹ 22 more rows\n# ℹ 7 more variables: `Goal Difference` &lt;int&gt;, Points &lt;int&gt;, ...11 &lt;dbl&gt;,\n#   ...12 &lt;dbl&gt;, ...13 &lt;dbl&gt;, ...14 &lt;dbl&gt;, ...15 &lt;chr&gt;\n\n\n\n\nAbove we have used a for loop to clean the data which included changing the names of colums and filtering. We now have all the 8 group stages statistics for the 2022 WC which include: “Rank”, “Squad”, “Matches Played”, “Wins”, “Draws”, “Losses”, “Goals For”, “Goals Against”, “Goal Difference”, “Points”. We also combined all the groups into a single tibble.\n\n\nIn conclusion, we hope to create interesting data visualizations as well as find our which metrics affect the probability of entering the knockout/semi-final/advanced stages. We will also later on add more data such as player statistics to see any further patterns in the data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MP3 DS2",
    "section": "",
    "text": "Maroova Elkemary\n\n\n\n\nHi! My name is Maroova Elkemary. I am a data enthusiast and love to combine data science with different realms such as video games, finance, sports, and music!\n\n\n\n\nI have had two data analysis work experiences so far where I worked with SQL, Python, and mostly focused on machine learning. I will show you a few of my data science projects so far in my school work!\n\n\n   GitHub Profile"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "MP3 DS2",
    "section": "",
    "text": "Maroova Elkemary\n\n\n\n\nHi! My name is Maroova Elkemary. I am a data enthusiast and love to combine data science with different realms such as video games, finance, sports, and music!\n\n\n\n\nI have had two data analysis work experiences so far where I worked with SQL, Python, and mostly focused on machine learning. I will show you a few of my data science projects so far in my school work!\n\n\n   GitHub Profile"
  }
]